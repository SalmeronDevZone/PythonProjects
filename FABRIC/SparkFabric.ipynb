{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717abe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"Files/orders/2019.csv\")\n",
    "# df now is a Spark DataFrame containing CSV data from \"Files/orders/2019.csv\".\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0349d",
   "metadata": {},
   "source": [
    "Este c√≥digo lee un archivo CSV llamado 2019.csv desde la carpeta Files/orders/ y lo carga como un DataFrame de Spark (una tabla en memoria).\n",
    "\n",
    "    .format(\"csv\"): dice que el archivo es formato CSV.\n",
    "\n",
    "    .option(\"header\", \"true\"): indica que la primera fila del CSV tiene los nombres de las columnas.\n",
    "\n",
    "    .load(...): carga el archivo.\n",
    "\n",
    "Luego, con display(df) puedes ver los datos en forma de tabla.\n",
    "\n",
    "üí° En resumen: Carga un archivo CSV como tabla en Spark y muestra su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "orderSchema = StructType([\n",
    "    StructField(\"SalesOrderNumber\", StringType()),\n",
    "    StructField(\"SalesOrderLineNumber\", IntegerType()),\n",
    "    StructField(\"OrderDate\", DateType()),\n",
    "    StructField(\"CustomerName\", StringType()),\n",
    "    StructField(\"Email\", StringType()),\n",
    "    StructField(\"Item\", StringType()),\n",
    "    StructField(\"Quantity\", IntegerType()),\n",
    "    StructField(\"UnitPrice\", FloatType()),\n",
    "    StructField(\"Tax\", FloatType())\n",
    "])\n",
    "\n",
    "df = spark.read.format(\"csv\").schema(orderSchema).load(\"Files/orders/2019.csv\")\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a39d9",
   "metadata": {},
   "source": [
    "El c√≥digo define un esquema personalizado (con nombres y tipos de columnas) y luego lee un archivo CSV (2019.csv) usando ese esquema, asumiendo que el archivo no tiene encabezado. Finalmente, muestra el contenido como una tabla con display(df)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afde459",
   "metadata": {},
   "source": [
    "Es c√≥digo anterior solo afecta al csv generado para el a√±o 2019, \n",
    "df = spark.read.format(\"csv\").schema(orderSchema).load(\"Files/orders/*.csv\")\n",
    "A√±adiendo esa linea de c√≥digo, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = df['CustomerName', 'Email']\n",
    "\n",
    "print(customers.count())\n",
    "print(customers.distinct().count())\n",
    "\n",
    "display(customers.distinct())\n",
    "\n",
    "# customers = df.select(\"CustomerName\", \"Email\")\n",
    "# Obtiene el mismo resultado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = df.select(\"CustomerName\", \"Email\").where(df['Item']=='Road-250 Red, 52')\n",
    "print(customers.count())\n",
    "print(customers.distinct().count())\n",
    "\n",
    "display(customers.distinct())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8779e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "productSales = df.select(\"Item\", \"Quantity\").groupBy(\"Item\").sum()\n",
    "\n",
    "display(productSales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "yearlySales = df.select(year(col(\"OrderDate\")).alias(\"Year\")).groupBy(\"Year\").count().orderBy(\"Year\")\n",
    "\n",
    "display(yearlySales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a408cd3f",
   "metadata": {},
   "source": [
    "El c√≥digo cuenta cu√°ntas √≥rdenes (ventas) hubo por a√±o a partir de la columna OrderDate del DataFrame df. Primero, extrae solo el a√±o de cada fecha con year(col(\"OrderDate\")) y lo renombra como \"Year\". Luego, agrupa todas las filas por ese a√±o con .groupBy(\"Year\"), y cuenta cu√°ntas filas (ventas) hay en cada grupo usando .count(). Despu√©s, ordena los resultados por a√±o con .orderBy(\"Year\"), y finalmente, con display(yearlySales) muestra una tabla con dos columnas: el a√±o (Year) y cu√°ntas √≥rdenes hubo ese a√±o (count).\n",
    "\n",
    "Es como decir: ‚ÄúMu√©strame cu√°ntas ventas se hicieron cada a√±o, ordenadas cronol√≥gicamente.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Create Year and Month columns\n",
    "transformed_df = df.withColumn(\"Year\", year(col(\"OrderDate\"))).withColumn(\"Month\", month(col(\"OrderDate\")))\n",
    "\n",
    "# Create the new FirstName and LastName fields\n",
    "transformed_df = transformed_df.withColumn(\"FirstName\", split(col(\"CustomerName\"), \" \").getItem(0)).withColumn(\"LastName\", split(col(\"CustomerName\"), \" \").getItem(1))\n",
    "\n",
    "# Filter and reorder columns\n",
    "transformed_df = transformed_df[\"SalesOrderNumber\", \"SalesOrderLineNumber\", \"OrderDate\", \"Year\", \"Month\", \"FirstName\", \"LastName\", \"Email\", \"Item\", \"Quantity\", \"UnitPrice\", \"Tax\"]\n",
    "\n",
    "# Display the first five orders\n",
    "display(transformed_df.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13ca02",
   "metadata": {},
   "source": [
    "Este c√≥digo transforma un DataFrame df que contiene informaci√≥n de √≥rdenes de venta para hacerlo m√°s √∫til y organizado.\n",
    "\n",
    "    Se crean nuevas columnas de fecha:\n",
    "    Usando la columna OrderDate, se crean dos columnas nuevas llamadas Year (a√±o) y Month (mes) con .withColumn(...) usando las funciones year() y month().\n",
    "\n",
    "    Se separa el nombre completo del cliente:\n",
    "    A partir de la columna CustomerName (por ejemplo, \"Ana Garc√≠a\"), se separan el primer nombre (FirstName) y el apellido (LastName) usando split(...). El primer espacio separa el nombre y el apellido. Por ejemplo:\n",
    "\n",
    "        \"Carlos Rivera\" ‚Üí FirstName = \"Carlos\", LastName = \"Rivera\"\n",
    "\n",
    "    Se reorganizan las columnas:\n",
    "    Se eligen y ordenan solo las columnas que se quieren mostrar: n√∫mero de orden, fecha, nombre del cliente, producto, precio, impuestos, etc.\n",
    "\n",
    "    Se muestran las primeras 5 √≥rdenes:\n",
    "    Con transformed_df.limit(5) se seleccionan solo las primeras 5 filas, y display(...) muestra el resultado en una tabla.\n",
    "\n",
    "üßæ Resultado final:\n",
    "\n",
    "Una tabla con 5 filas (√≥rdenes) que muestra columnas limpias y organizadas como:\n",
    "\n",
    "        SalesOrderNumber\tSalesOrderLineNumber\tOrderDate\tYear\tMonth\tFirstName\tLastName\tEmail\tItem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afb31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.write.mode(\"overwrite\").parquet('Files/transformed_data/orders')\n",
    "\n",
    "print (\"Transformed data saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e20af",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = spark.read.format(\"parquet\").load(\"Files/transformed_data/orders\")\n",
    "display(orders_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895cc3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.write.partitionBy(\"Year\",\"Month\").mode(\"overwrite\").parquet(\"Files/partitioned_data\")\n",
    "\n",
    "print (\"Transformed data saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_2021_df = spark.read.format(\"parquet\").load(\"Files/partitioned_data/Year=2021/Month=*\")\n",
    "\n",
    "display(orders_2021_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ff0f3b",
   "metadata": {},
   "source": [
    "# TRABAJAR CON SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new table\n",
    "df.write.format(\"delta\").saveAsTable(\"salesorders\")\n",
    "\n",
    "# Get the table description\n",
    "spark.sql(\"DESCRIBE EXTENDED salesorders\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT YEAR(OrderDate) AS OrderYear,\n",
    "       SUM((UnitPrice * Quantity) + Tax) AS GrossRevenue\n",
    "FROM salesorders\n",
    "GROUP BY YEAR(OrderDate)\n",
    "ORDER BY OrderYear;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90535eb",
   "metadata": {},
   "source": [
    "# MATPLOTLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = \"SELECT CAST(YEAR(OrderDate) AS CHAR(4)) AS OrderYear, \\\n",
    "                SUM((UnitPrice * Quantity) + Tax) AS GrossRevenue, \\\n",
    "                COUNT(DISTINCT SalesOrderNumber) AS YearlyCounts \\\n",
    "            FROM salesorders \\\n",
    "            GROUP BY CAST(YEAR(OrderDate) AS CHAR(4)) \\\n",
    "            ORDER BY OrderYear\"\n",
    "df_spark = spark.sql(sqlQuery)\n",
    "df_spark.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae42a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# matplotlib requires a Pandas dataframe, not a Spark one\n",
    "df_sales = df_spark.toPandas()\n",
    "\n",
    "# Create a bar plot of revenue by year\n",
    "plt.bar(x=df_sales['OrderYear'], height=df_sales['GrossRevenue'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed6e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Clear the plot area\n",
    "plt.clf()\n",
    "\n",
    "# Create a bar plot of revenue by year\n",
    "plt.bar(x=df_sales['OrderYear'], height=df_sales['GrossRevenue'], color='orange')\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Revenue by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Revenue')\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Clear the plot area\n",
    "plt.clf()\n",
    "\n",
    "# Create a Figure\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "\n",
    "# Create a bar plot of revenue by year\n",
    "plt.bar(x=df_sales['OrderYear'], height=df_sales['GrossRevenue'], color='orange')\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Revenue by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Revenue')\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6114af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Clear the plot area\n",
    "plt.clf()\n",
    "\n",
    "# Create a figure for 2 subplots (1 row, 2 columns)\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4))\n",
    "\n",
    "# Create a bar plot of revenue by year on the first axis\n",
    "ax[0].bar(x=df_sales['OrderYear'], height=df_sales['GrossRevenue'], color='orange')\n",
    "ax[0].set_title('Revenue by Year')\n",
    "\n",
    "# Create a pie chart of yearly order counts on the second axis\n",
    "ax[1].pie(df_sales['YearlyCounts'])\n",
    "ax[1].set_title('Orders per Year')\n",
    "ax[1].legend(df_sales['OrderYear'])\n",
    "\n",
    "# Add a title to the Figure\n",
    "fig.suptitle('Sales Data')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c775d",
   "metadata": {},
   "source": [
    "# SEABORN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Clear the plot area\n",
    "plt.clf()\n",
    "\n",
    "# Create a bar chart\n",
    "ax = sns.barplot(x=\"OrderYear\", y=\"GrossRevenue\", data=df_sales)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Clear the plot area\n",
    "plt.clf()\n",
    "\n",
    "# Set the visual theme for seaborn\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar chart\n",
    "ax = sns.barplot(x=\"OrderYear\", y=\"GrossRevenue\", data=df_sales)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Clear the plot area\n",
    "plt.clf()\n",
    "\n",
    "# Create a line chart\n",
    "ax = sns.lineplot(x=\"OrderYear\", y=\"GrossRevenue\", data=df_sales)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
